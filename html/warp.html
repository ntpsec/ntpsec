<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="content-type" content="text/html;charset=iso-8859-1">
<meta name="generator" content="HTML Tidy, see www.w3.org">
<title>How NTP Works</title>
<link href="scripts/style.css" type="text/css" rel="stylesheet">
</head>
<body>
<h3>How NTP Works</h3>
<p>Last update:
  <!-- #BeginDate format:En2m -->30-Sep-2010  21:39<!-- #EndDate -->
  UTC</p>
<h4>Table of Contents</h4>
<ul>
  <li class="inline"><a href="#intro">Introduction and Overview</a></li>
  <li class="inline"><a href="#budget">Statistics Budget</a></li>
  <li class="inline"><a href="#quality">Quality of Service</a></li>
  <li class="inline"><a href="#prefer">Mitigation Algorithm</a></li>
  <li class="inline"><a href="#clock">Clock Discipline Algorithm</a></li>
  <li class="inline"><a href="#state">Clock State Machine</a></li>
</ul>
<hr>
<h4 id="intro">Introduction and Overview</h4>
<p>NTP time synchronization services are widely available in the public Internet. The public NTP subnet in late 2010 includes several thousand servers in most countries and on every continent of the globe, including Antarctica, and sometimes in space and on the sea floor. These servers support a total population estimated at over 25 million computers in the global Internet.</p>
<p> The NTP subnet operates with a hierarchy of levels, where each level is assigned a number called the stratum. Stratum 1 (primary) servers at the lowest level are directly synchronized to national time services via satellite, radio and telephone mdem. Stratum 2 (secondary) servers at the next higher level are synchronize to stratum 1 servers and so on. Normally, NTP clients and servers with a relatively small number of clients do not synchronize to public primary servers. There are several hundred public secondary servers operating at higher strata and are the preferred choice.</p>
<p>This page presents an overview of the NTP daemon included in this distribution. We refer to this as the <em>reference implementation</em> only because it was  used to test and validate the NTPv4 specification RFC-5905. It is best read in conjunction with the briefings on the <a href="http://www.eecis.udel.edu/~mills/ntp.html">Network Time Synchronization Research Project</a> page.</p>
<div align="center">
  <p><img src="pic/fig_3_1.gif" alt="gif"></p>
  <p>Figure 1. NTP Daemon Processes and Algorithms</p>
</div>
<p>The overall organization of the NTP daemon is shown in Figure 1. It is useful in this context to consider the daemon as both a client of upstream servers and as a server for downstream clients. It includes a pair of peer/poll processes for each reference clock or remote  server used as a synchronization source. The poll process sends NTP packets at intervals ranging from 8 s to 36 hr. The peer process receives NTP packets and runs the on-wire protocol that collects four timestamps: the <em>origin timestamp</em> <em>T</em><sub>1</sub> upon departure of the client request, the <em>receive timestamp</em> <em>T</em><sub>2</sub> upon arrival at the server, the <em>transmit timestamp</em> <em>T</em><sub>3</sub> upon departure of the server reply, and the <em>destination timestamp</em> <em>T</em><sub>4</sub> upon arrival at the client. These timestamps are used to calculate the clock offset and roundtrip delay:</p>
<div align="center">
  <p>offset = [(<em>T</em><sub>2</sub> -<em> T</em><sub>1</sub>) + (<em>T</em><sub>3</sub> - <em>T</em><sub>4</sub>)] / 2<br>
    delay = (<em>T</em><sub>4</sub> - <em>T</em><sub>1</sub>) - (<em>T</em><sub>3</sub> - <em>T</em><sub>2</sub>).</p>
</div>
<p>The  algorithm described on the <a href="filter.html">Clock Filter Algorithm</a> page  uses a window of offset and delay samples to select the best ones. Those sources that have passed a number of sanity checks are declared <em>selectable</em>. From the selectable population the statistics are used by the algorithm described on the <a href="select.html">Clock Select Algorithm</a> page to determine a number of <em>truechimers</em> according to correctness principles. From the truechimer population the algorithm described on the <a href="cluster.html">Clock Cluster Algorihtm</a> page determines a number of <em>survivors</em>  on the basis of statistical clustering principles. The algorithms described on the <a href="prefer.html">Mitigation Rules and the <tt>prefer</tt> Keyword</a> page combine the survivor offsets, designate one of them as the <em>system peer</em> and produces the final offset used by the algorithm described on the <a href="discipline.html">Clock Discipline Algorithm</a> page to adjust the system clock time and frequency. For additional details about these algorithms, see the Architecture Briefing on the <a href="htttp://www.eecis.udel.edu/~mills/ntp.html">Network Time Synchronization Research Project</a> page.</p>
<h4 id="budget">Statistics Budget</h4>
<p>Each source is characterized by the  offset and  delay measured by the on-wire protocol and the  dispersion and jitter calculated by the clock filter algorithm. This algorithm  selects the offset sample with the lowest  delay, which generally represents the most accurate data, so it and the  associated offset  sample become the peer variables of the same name. The peer dispersion  is determined as a weighted average of the dispersion samples in the shift register.  It continues to grow at the same  rate as the sample dispersion. Finally, the peer jitter is determined as the root-mean-square (RMS) average of  the offset samples in the shift register relative to the selected offset sample.</p>
<p> The clock filter algorithm continues to process packets in this way until the source is no longer reachable. Reachability is determined by an eight-bit shift register, which is shifted left by one bit as each poll packet is sent, with 0 replacing the vacated rightmost bit. Each time an update is received, the rightmost bit is set to 1. The source is considered reachable if any bit is set to 1 in the register; otherwise, it is considered unreachable.</p>
<p> A server is considered selectable only if it is reachable and a timing loop would not be created. A timing loop occurs when the server is apparently synchronized to the client or when the server is synchronized to the same server as the client. When a source is unreachable, a  dummy sample with  &quot;infinite&quot; dispersion  is inserted in the shift register at each poll, thus displacing old samples.</p>
<p>The composition of  the survivor population and the system peer selection is redetermined as each update from each source is received. The system variables are copied from the  system peer variables of the same name and the system stratum set one greater than the system peer stratum. Like  peer dispersion, the system dispersion increases at the same rate so, even if all sources have become unreachable, the daemon appears to upstratum clients at ever increasing dispersion.</p>
<h4 id="quality">Quality of Service</h4>
<p>Of interest in this discussion is how the protocol determines the quality of service from a particular reference clock or remote server. It is determined from two statistics, <em>expected error</em> and <em>maximum error.</em> Expected error is determined from various jitter components; it represents the nominal error in determining the mean clock offset. However, it is not relevant to  the discussion to follow. Maximum error is determined from delay and dispersion contributions and represents the worst-case error due to all causes. In order to simplify this presentation, certain minor contribution s to the maximum error statistic are ignored. Elsewhere in this documentation the maximum error is called <em>synchronization distance</em>.</p>
<p>The maximum error  is  computed as one-half the <em>root delay</em> to the primary source of time; i.e., the primary reference clock, plus the <em>root dispersion</em>.   The root variables are included in the NTP packet header received from each server. When calculating  maximum error, the  root delay is the sum of the root delay in the packet and the peer  delay, while the root dispersion is the sum of the root dispersion in the packet and the peer dispersion. </p>
<p>A source is considered selectable only if its maximum error is less than the <em>select threshold</em>, by default 1.5 s, but can be changed according to client preference. A common  consequences is when an upstream server loses all sources and its maximum error apparent to clients begins to increase. The clients are not aware of  this condition and  continues to accept synchronization as long as the maximum error is less than the select threshold.</p>
<p>Although it might seem counter-intuitive, a cardinal rule in the selection process is, once a sample has been selected by the clock filter algorithm,  older samples are no longer selectable. This applies also to the select algorithm. Once the peer variables for a source have been selected, older variables of the same or other sources are no longer selectable. This means that not every sample can be used to update the peer variables and up to seven samples can be ignored between selected samples. This fact has been carefully considered in the discipline algorithm design with due consideration of the feedback loop delay and minimum sampling rate. In engineering terms, even if only one sample in eight survives, the resulting sample rate is twice the Nyquist rate at any time constant and poll interval.</p>
<h4 id="prefer">Mitigation Algorithms</h4>
<p>Some daemon configurations include a combination of  reference clocks and remote servers in order to provide redundancy and backup. For example, a modem reference clock may furnish backup for a GPS reference clock, but used only if the GPS clock fails. In addition, the local clock  might be used if all sources fail, or orphan mode might be used instead. The mitigation algorithms provide an orderly selection in such cases. Another function of these algorithms is when multiple sources of the same type are available, but for one reason or another, one or more of them are  preferred over the others. Finally, some reference clocks provide a pulse-per-second (PPS) signal to augment the serial timecode. The mitigation algorithms have to figure out when the PPS signal is valid and which reference clock is to number the seconds. These intricate algorithms are described on the <a href="prefer.html">Mitigation Algorithms and the <tt>prefer</tt> Keyword</a> page.</p>
<h4 id="clock">Clock Discipline Algorithm</h4>
<p>At the heart of the NTP specification and reference implementation is the clock discipline algorithm, which is best described as an adaptive parameter, hybrid phase/frequency-lock feedback loop. It is an intricately crafted algorithm that automatically  adapts  for optimum performance while  minimizing network overhead. Further details are on the <a href="discipline.html">Clock Discipline</a> page.</p>
<h4 id="state">Clock State Machine</h4>
<p>In the NTPv4 specification and reference implementation a state machine is used to manage the system clock under exceptional conditions, as when the daemon is first started or when encountering  severe network congestion. When the frequency file is present at  startup is that the residual offset error is less than 0.5 ms within 300 s. When the frequency file is not present, this result is achieved within 600 s. Further details are on the <a href="clock.html">Clock State Machine</a> page.</p>
<hr>
<script type="text/javascript" language="javascript" src="scripts/footer.txt"></script>
</body>
</html>
